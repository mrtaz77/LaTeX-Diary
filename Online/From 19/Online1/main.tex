\documentclass{article}
\usepackage{graphicx} % Required for inserting images
\usepackage{amssymb,amsmath}
\usepackage{multirow,multicol}
\usepackage{verbatim}
\usepackage{biblatex}
\usepackage{authblk}
\usepackage{enumitem}
\usepackage{hyperref}
\usepackage{xcolor} % coloring text
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage{algorithm}
%\usepackage[algo2e]{algorithm2e} 
\usepackage{arevmath}     % For math symbols
\usepackage[noend]{algpseudocode}

\title{
\raggedright{Point Cloud Sampling Network}\\
}
% numbering in authors
\author[a]{\raggedright{Huang}}
\author[a,*]{\raggedright{Yong Liua}}
\author[a,b]{\raggedright{Jie Liang}}
\affil[a]{\raggedright{Laboratory of Advanced Perception on Robotics and Intelligent Learning, College of Control Science and Engineering, Zhejiang University, Hangzhou, China}}
\affil[b]{\raggedright{Institute of Mechanical and Electrical Engineering, Beijing, China}}
\date{}
\begin{document}

\maketitle
\section{Abstract}
The increasing number of points in 3D point clouds has brought great challenges for subsequent algorithm efficiencies. Down-sampling algorithms are adopted to simplify the data and accelerate the computation.

\begin{multicols}{2}
\section{Methodology}
\subsection{Basic Pipeline}
The basic pipeline of FPN is presented in Fig. 2. We aggregate global features from the input points with a set of multilevel perceptions (MLPs) and Max Pooling following
PointNet .

\subsection{Hybrid Training Strategy}
The achievement of HTS is presented as Algorithm 9.

\subsection{Loss function}
The range constraint can be presented as 

\begin{equation}
    \mathcal{L}_{rc} = \frac{1}{N} \sum{||S_{o} - S_{i}||_{2}}
\end{equation}

For reconstructionrelated tasks, it may be Chamfer Distance or Earth Mover Distance [22] defined as

\begin{equation}
\begin{split}
    \mathcal{L}_{task} &= L_{CD}(S_1,S_2) \\
        &= \frac{1}{2} \left( \frac{1}{|S_1|} \sum_{x\in S_1} min_{y \in S_2}||x-y||_2 + \frac{1}{|S_2|} \sum_{x \in S_2} min_{y \in S_2 } ||x-y||_2 \right)
\end{split}
\end{equation}
or
\begin{equation}
     \mathcal{L}_{task} = L_{EMD}(S_1,S_2) = min_{\phi ; S_1 \rightarrow S_2} \frac{1}{|S_1|} \sum_{x \in S_1} ||x-\phi(x)||_2
\end{equation}
    
\end{multicols}

\begin{algorithm}
    \caption{Training with Hybrid Training Strategy}
    \hspace*{\algorithmicindent} \textbf{Input} data \textit{X}, the number of iterations \textit{iter}, the number of resolutions \textit{m};\\
    $prob_1,prob_2,\ldots,prob_m = \frac{1}{m},\frac{1}{m},\ldots,\frac{1}{m}$\\
    \For{$i=1$ \textbf{to} $iter$}
    \State Select the resolution $r$ according to \newline  $prob_1, \ldots, prob_m$;
    \State Train FPN by descending gradient: $\Delta_\theta_{FPN}\mathcal{L}_{loss} (Y_{X,r})$
\EndFor
\end{algorithm}



\end{document}

